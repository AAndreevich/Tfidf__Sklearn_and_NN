# Tfidf__Sklearn_and_NN_in_NLP

* Задание 1.

**Задание**: обучите три классификатора:

1) на токенах с высокой частотой

2) на токенах со средней частотой

3) на токенах с низкой частотой


Сравните полученные результаты, оцените какие токены наиболее важные для классификации.


* Задание 2.

найти фичи с наибольшей значимостью, и вывести их


* Задание 3.

1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)

2) подобрать оптимальный размер для hashing векторайзера

3) убедиться что для сетки нет переобучения

Вывод:

График функции потерь четко отражает хорошую обучаемость NN на тренировочных данных, но очень плохо справляется с тестовыми данными, это чвязано с малым объемом выборки используемой для обучения модели. Аналогичный пример обработки данных с большим объемом данных представлен [здесь](https://colab.research.google.com/drive/1c3CN3kBfnAuI7XSUS2Uw-Zl6zjJCgvpZ): где на [графике](https://colab.research.google.com/drive/1c3CN3kBfnAuI7XSUS2Uw-Zl6zjJCgvpZ#scrollTo=Ro8iJKYCKGZU) можно увидеть улучшение результатов при условии увеличенного объема данных

Код на collab
https://colab.research.google.com/drive/1-6J1hSuhOoySpNFEbMRWdz5Yz99Y7Wti?usp=sharing

